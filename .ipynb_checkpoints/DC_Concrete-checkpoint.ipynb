{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import uncertainty_libr as unc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erfinv\n",
    "from math import sqrt, erf\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from math import pi\n",
    "from sklearn import metrics as me\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"Data/Uncertainty/Concrete_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_dataset,test_dataset = train_test_split(dataset,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = 'Concrete compressive strength(MPa, megapascals) '\n",
    "input_column = train_dataset.columns.drop([label_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_dataset[input_column].astype(np.float32)\n",
    "y_train = train_dataset[label_column].astype(np.float32)\n",
    "\n",
    "x_test = test_dataset[input_column].astype(np.float32)\n",
    "y_test = test_dataset[label_column].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Certainty Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECE_normal_loss(y_actual,y_pred):\n",
    "    return unc.tf_ECE(y_actual[:,0],y_pred[:,0],y_pred[:,1],'normal',RMSE_mult=1,CE_mult=1,mpiw_mult=0.125)\n",
    "\n",
    "def ECE_logistic_loss(y_actual,y_pred):\n",
    "    return unc.tf_ECE(y_actual[:,0],y_pred[:,0],y_pred[:,1],'logistic',RMSE_mult=1,CE_mult=1,mpiw_mult=0.05)\n",
    "\n",
    "def ECE_shifted_rayleigh_loss(y_actual,y_pred):\n",
    "    return unc.tf_ECE(y_actual[:,0],y_pred[:,0],y_pred[:,1],'shifted_rayleigh',RMSE_mult=1,CE_mult=1,mpiw_mult=0.1)\n",
    "\n",
    "def QD_loss(y_actual,y_pred):\n",
    "    return unc.tf_qd(y_actual[:,0],y_pred[:,0],y_pred[:,1],lambda_=0.40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Preprocessing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = True\n",
    "if scale:\n",
    "    x_scaler = preprocessing.MinMaxScaler((0, 1))\n",
    "    y_scaler = preprocessing.MinMaxScaler((0, 1))\n",
    "\n",
    "    processed_x_train = x_scaler.fit_transform(x_train)\n",
    "    processed_y_train = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "    processed_x_test = x_scaler.transform(x_test)\n",
    "    processed_y_test = y_scaler.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "else:\n",
    "    processed_x_train = x_train.values\n",
    "    processed_y_train = y_train.values.reshape(-1, 1)\n",
    "\n",
    "    processed_x_test = x_test.values\n",
    "    processed_y_test = y_test.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dim = processed_x_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        processed_x_train,\n",
    "        processed_y_train\n",
    "    )\n",
    ").batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        processed_x_test,    \n",
    "        processed_y_test\n",
    "    )\n",
    ").batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. NN Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dim = processed_x_test.shape[1]\n",
    "LEARNING_RATE = 0.005\n",
    "DECAY = 0.98\n",
    "N_EPOCHS = 800\n",
    "TOLERANCE = 0.005\n",
    "early_stopping = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y,distr):\n",
    "\n",
    "    if distr==\"shifted_rayleigh\":\n",
    "        return ECE_shifted_rayleigh_loss(y,model(x))\n",
    "    elif distr==\"logistic\":\n",
    "        return ECE_logistic_loss(y,model(x))\n",
    "    elif distr=='normal':\n",
    "        return ECE_normal_loss(y,model(x))\n",
    "\n",
    "    #return QD_loss(y,model(x))\n",
    "\n",
    "def grad(model, inputs, targets,distr):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets,distr)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DC_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(inp_dim, activation='relu'),\n",
    "        tf.keras.layers.Dense(50, activation='relu'),\n",
    "        tf.keras.layers.Dense(2, activation='linear',bias_initializer=tf.keras.initializers.Constant(value=[1.0,0.0])) \n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Runs = 5\n",
    "Ensembles = 5\n",
    "alpha=0.1\n",
    "distr=\"normal\"\n",
    "\n",
    "n_std_devs = sqrt(2.0)*erfinv(1-alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_t = []\n",
    "MAE_t = []\n",
    "ME_t =[]\n",
    "R2_t =[]\n",
    "pinaw_t = []\n",
    "pinaw_p_t = []\n",
    "picp_t = []\n",
    "adce_t = []\n",
    "dce_t = []\n",
    "\n",
    "eval_p = 0.95\n",
    "\n",
    "import tqdm\n",
    "optimizer = tf.keras.optimizers.Adam(lr=LEARNING_RATE, beta_1=DECAY)#0.0005)\n",
    "\n",
    "for i in range(Runs):\n",
    "    y_pred_all = []\n",
    "    \n",
    "    for j in range(Ensembles):\n",
    "        print(\"Starting run \"+str(i+1)+\" of \"+str(Runs)+\" -- with ensemble \"+str(j+1)+\" of \"+str(Ensembles))\n",
    "\n",
    "        real_model=DC_model()\n",
    "\n",
    "        # Keep results for plotting\n",
    "        real_train_loss_results = []\n",
    "        real_test_loss_results = []\n",
    "\n",
    "        for epoch in range(N_EPOCHS):\n",
    "            epoch_train_loss_avg = tf.keras.metrics.Mean()\n",
    "            epoch_test_loss_avg = tf.keras.metrics.Mean()\n",
    "            # Training loop - using batches of 32    \n",
    "\n",
    "            for x,y in train_dataset:#,ascii=True,desc='Training epoch '+str(epoch)):\n",
    "                # Optimize the model\n",
    "                loss_value, grads = grad(real_model, x, y,distr)\n",
    "                optimizer.apply_gradients(zip(grads, real_model.trainable_variables))\n",
    "                # Track progress\n",
    "                epoch_train_loss_avg(loss_value)  # Add current batch loss\n",
    "                # End epoch\n",
    "\n",
    "            for x,y in test_dataset:\n",
    "                # Optimize the model\n",
    "                loss_value = loss(real_model, x, y,distr)\n",
    "                # Track progress\n",
    "                epoch_test_loss_avg(loss_value)  # Add current batch loss\n",
    "                # End epoch\n",
    "\n",
    "            real_train_loss_results.append(epoch_train_loss_avg.result())\n",
    "            real_test_loss_results.append(epoch_test_loss_avg.result())\n",
    "\n",
    "            if epoch > 0:\n",
    "                if early_stopping and (real_test_loss_results[epoch] - min_real_test_loss_results > TOLERANCE * min_real_test_loss_results):\n",
    "                    print(f'Early stopping at epoch {epoch} using tolerance {TOLERANCE}.')\n",
    "                    print(\"Epoch {:03d}: Train Loss: {:.3f}\".format(epoch, epoch_train_loss_avg.result()))\n",
    "                    print(\"Epoch {:03d}: Test Loss: {:.3f}\".format(epoch, epoch_test_loss_avg.result()))\n",
    "                    break\n",
    "                else:\n",
    "                    min_real_test_loss_results = tf.minimum(min_real_test_loss_results, epoch_test_loss_avg.result())\n",
    "            else:\n",
    "                min_real_test_loss_results = epoch_test_loss_avg.result()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(\"Epoch {:03d}: Train Loss: {:.3f}\".format(epoch, epoch_train_loss_avg.result()))\n",
    "                print(\"Epoch {:03d}: Test Loss: {:.3f}\".format(epoch, epoch_test_loss_avg.result()))\n",
    "\n",
    "        print(\"\\n\")\n",
    "        pred_arr = processed_x_test\n",
    "        test_arr = processed_y_test\n",
    "        out=real_model.predict(pred_arr)\n",
    "\n",
    "        y_pred_all.append(out)\n",
    "        \n",
    "        print(\"PICP: \"+str(unc.PICP(out[:,0],out[:,1],test_arr[:,0])))\n",
    "        print(\"NMIPW: \"+str(unc.tf_PINAW_one_dim(test_arr[:,0],out[:,1],out[:,0]).numpy()))\n",
    "        res,values,ece,pinaw_plot,dce_width,widths=unc.tf_ce_plot(test_arr,out[:,0],out[:,1],'normal')\n",
    "        print(\"ACE: \"+str(ece.numpy()))\n",
    "        print(\"\\n\")\n",
    "\n",
    "    y_pred_all = tf.convert_to_tensor(y_pred_all,dtype=np.float32)\n",
    "\n",
    "    upper = tf.reduce_mean(y_pred_all[:,:,0],axis=0)+n_std_devs*tf.math.reduce_std(y_pred_all[:,:,0],axis=0)/tf.math.sqrt(float(y_pred_all.shape[0]))\n",
    "    lower = tf.reduce_mean(y_pred_all[:,:,1],axis=0)-n_std_devs*tf.math.reduce_std(y_pred_all[:,:,1],axis=0)/tf.math.sqrt(float(y_pred_all.shape[0]))\n",
    "\n",
    "    up_temp = tf.math.maximum(upper,lower)\n",
    "    lower = tf.math.minimum(upper,lower)\n",
    "    upper=up_temp\n",
    "    \n",
    "    distr = 'normal'\n",
    "\n",
    "    #pinaw = unc.tf_PINAW_one_dim(test_arr[:,0],upper,lower).numpy()\n",
    "    sigm = unc.tf_calculate_sigma(upper,lower,distr)\n",
    "    Y_pred,diff=unc.tf_calculate_mean(upper,lower,sigm,distr)\n",
    "    dce = 2*np.mean(res-values)\n",
    "    \n",
    "    if distr ==\"logistic\":\n",
    "        p_low = (1-eval_p)/2\n",
    "        p_up = (1+eval_p)/2\n",
    "        upper_p=Y_pred+sigm*np.log(p_up/(1-p_up))\n",
    "        lower_p=Y_pred+sigm*np.log(p_low/(1-p_low))\n",
    "        \n",
    "    elif distr ==\"shifted_rayleigh\":\n",
    "        p_low = (1-eval_p)/2\n",
    "        p_up = (1+eval_p)/2\n",
    "        upper_p=Y_pred-sigm+sqrt(-2*np.log(1-p_up))*sigm\n",
    "        lower_p=Y_pred-sigm+sqrt(-2*np.log(1-p_low))*sigm\n",
    "        \n",
    "    elif distr ==\"normal\":\n",
    "        upper_p=Y_pred+sigm*sqrt(2)*erfinv(eval_p)\n",
    "        lower_p=Y_pred-sigm*sqrt(2)*erfinv(eval_p)\n",
    "    \n",
    "    \n",
    "    pinaw = unc.tf_PINAW_one_dim(test_arr[:,0],upper_p,lower_p).numpy()\n",
    "    sigm = unc.tf_calculate_sigma(upper,lower,distr)\n",
    "    Y_pred,diff=unc.tf_calculate_mean(upper,lower,sigm,distr)\n",
    "    res,values,adce,pinaw_plot,dce_width,widths=unc.tf_ce_plot(test_arr,upper,lower,distr)\n",
    "    pinaw_p = pinaw_plot[np.where(res.numpy()>=eval_p)[0][0]].numpy()\n",
    "    dce = 2*np.mean(res-values)\n",
    "    hard_picp = unc.PICP(upper_p,lower_p,test_arr[:,0])\n",
    "    R2_total,RMSE_total,MAE_total,ME_total = unc.scores_calc_print(y_scaler.inverse_transform(Y_pred.numpy().reshape(-1,1)),y_scaler.inverse_transform(test_arr),False)\n",
    "\n",
    "\n",
    "    RMSE_t = np.append(RMSE_t,RMSE_total)\n",
    "    MAE_t = np.append(MAE_t,MAE_total)\n",
    "    ME_t =np.append(ME_t,ME_total)\n",
    "    R2_t =np.append(R2_t,R2_total)\n",
    "    pinaw_t = np.append(pinaw_t,pinaw)\n",
    "    pinaw_p_t = np.append(pinaw_p_t,pinaw_p)\n",
    "    picp_t = np.append(picp_t,hard_picp)\n",
    "    adce_t = np.append(adce_t,adce)\n",
    "    dce_t = np.append(dce_t,dce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(10*\"-\"+\"RESULTS of \"+str(Runs)+\" runs\"+10*\"-\")\n",
    "print(f\"RMSE: {np.mean(RMSE_t):.3f} +/- ({np.std(RMSE_t)/np.sqrt(Runs):.3f})\")\n",
    "print(f\"MAE: {np.mean(MAE_t):.3f} +/- ({np.std(MAE_t)/np.sqrt(Runs):.3f})\")\n",
    "print(f\"ME: {np.mean(ME_t):.3f} +/- ({np.std(ME_t)/np.sqrt(Runs):.3f})\")\n",
    "print(f\"R2: {np.mean(R2_t):.3f} +/- ({np.std(R2_t)/np.sqrt(Runs):.3f})\")\n",
    "print(f\"NMPIW: {np.mean(pinaw_t):.3f} +/- ({np.std(pinaw_t)/np.sqrt(Runs):.3f})\")\n",
    "print(f\"NMPIW_p: {np.mean(pinaw_p_t):.3f} +/- ({np.std(pinaw_p_t)/np.sqrt(Runs):.3f})\")\n",
    "print(f\"PICP: {np.mean(picp_t):.3f} +/- ({np.std(picp_t)/np.sqrt(Runs):.3f})\")\n",
    "print(f\"ADCE: {np.mean(adce_t):.3f} +/- ({np.std(adce_t)/np.sqrt(Runs):.3f})\")\n",
    "print(f\"DCE: {np.mean(dce_t):.3f} +/- ({np.std(dce_t)/np.sqrt(Runs):.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. NN Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res,values,adce,pinaw_plot,dce_width,widths=unc.tf_ce_plot(test_arr,upper,lower,distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "ax = plt.gca()\n",
    "print(\"--\")\n",
    "\n",
    "#diff = np.sum(np.abs(np.subtract(values,res)))\n",
    "print(\"NN ACE: \"+str(adce.numpy()))\n",
    "#print(\"NN CE: \"+str(ce))\n",
    "plt.plot(np.arange(0,1.0,1.0/len(values)),res,label='NN')\n",
    "plt.plot(np.arange(0,1.0,1.0/len(values)),values,label='Optimal',color='gray')\n",
    "#plt.scatter(0.9,soft_picp,marker=\"x\",color='red',s=100)\n",
    "#plt.xticks(np.arange(0, 1.1, 0.1),np.round(values[0::100],2))#, np.round(values[0::10],2))\n",
    "#plt.locator_params(axis='x', nbins=len(values)/10)\n",
    "plt.xlabel('Size of prediction interval ')\n",
    "plt.ylabel('Percentage of points within ')\n",
    "    \n",
    "plt.legend(loc='lower right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "ax = plt.gca()\n",
    "\n",
    "#diff = np.sum(np.abs(np.subtract(values,res)))\n",
    "print(\"NN PINAW: \"+str(pinaw))\n",
    "#print(\"NN CE: \"+str(ce))\n",
    "plt.plot(np.arange(0,1.0,1.0/len(values)),pinaw_plot,label='NN')\n",
    "plt.plot(np.arange(0,1.0,1.0/len(values)),widths,label='Optimal')\n",
    "plt.scatter(0.9,pinaw,marker=\"x\",color='red',s=100)\n",
    "#plt.xticks(np.arange(0, 1.1, 0.1),np.round(values[0::100],2))#, np.round(values[0::10],2))\n",
    "#plt.locator_params(axis='x', nbins=len(values)/10)\n",
    "plt.xlabel('Size of prediction interval ')\n",
    "plt.ylabel('Normalized PI width')\n",
    "    \n",
    "plt.legend(loc='lower right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 20\n",
    "plt.errorbar(processed_y_test[start:end]/y_scaler.scale_,Y_pred[start:end]/y_scaler.scale_,yerr=np.array([Y_pred-lower,upper-Y_pred])[:,start:end]/y_scaler.scale_, fmt='o',ecolor='green',label='Predicted (90% error)')\n",
    "plt.plot(np.arange(0,90,5),np.arange(0,90,5),color='red',label='Ideal')\n",
    "plt.xlabel(\"Target value\")\n",
    "plt.ylabel(\"Predicted value\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of parameters in the model {real_model.count_params()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
